# ====================================
# AI PROVIDER CONFIGURATION
# ====================================

# -----------------------------
# ANTHROPIC (PRIMARY PROVIDER)
# -----------------------------
# Get API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-api03-YOUR_KEY_HERE
ANTHROPIC_MODEL_OPUS=claude-opus-4-20250514
ANTHROPIC_MODEL_SONNET=claude-sonnet-4-5-20250514
ANTHROPIC_MODEL_HAIKU=claude-haiku-4-5-20250514
ANTHROPIC_ENABLED=true

# -----------------------------
# GOOGLE (SECONDARY PROVIDER)
# -----------------------------
# Get API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIzaSyYOUR_KEY_HERE
GOOGLE_MODEL_PRO=gemini-3-pro
GOOGLE_MODEL_FLASH=gemini-3-flash
GOOGLE_ENABLED=true

# -----------------------------
# OPENAI (TERTIARY PROVIDER)
# -----------------------------
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-YOUR_KEY_HERE
OPENAI_MODEL=gpt-5.1-turbo
OPENAI_ORGANIZATION=org-YOUR_ORG_ID  # Optional
OPENAI_ENABLED=true

# ====================================
# FALLBACK STRATEGY CONFIGURATION
# ====================================
AI_FALLBACK_ENABLED=true
AI_RETRY_ATTEMPTS=3
AI_TIMEOUT_MS=30000
AI_COST_OPTIMIZATION=true

# Circuit Breaker Settings
AI_CIRCUIT_BREAKER_ENABLED=true
AI_CIRCUIT_BREAKER_THRESHOLD=5
AI_CIRCUIT_BREAKER_RESET_MS=60000

# ====================================
# RATE LIMITING CONFIGURATION
# ====================================
AI_RATE_LIMITING_ENABLED=true

# Anthropic Rate Limits
ANTHROPIC_RATE_LIMIT_RPM=50      # Requests per minute
ANTHROPIC_RATE_LIMIT_TPM=100000  # Tokens per minute

# Google Rate Limits
GOOGLE_RATE_LIMIT_RPM=60
GOOGLE_RATE_LIMIT_TPM=100000

# OpenAI Rate Limits
OPENAI_RATE_LIMIT_RPM=60
OPENAI_RATE_LIMIT_TPM=150000

# ====================================
# MONITORING & LOGGING
# ====================================
AI_MONITORING_ENABLED=true
AI_LOG_LEVEL=info  # debug | info | warn | error
AI_METRICS_INTERVAL_MS=60000
AI_COST_TRACKING_ENABLED=true

# Alerting Thresholds
AI_ALERTING_ENABLED=true
AI_COST_ALERT_THRESHOLD=100     # Dollar amount per day
AI_ERROR_ALERT_THRESHOLD=10     # Errors per hour

# ====================================
# CACHING CONFIGURATION
# ====================================
AI_CACHING_ENABLED=true
AI_CACHE_TTL_SECONDS=3600
AI_CACHE_MAX_SIZE_MB=100

# Redis Cache (Optional - for distributed caching)
AI_REDIS_CACHE_ENABLED=false
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# ====================================
# SYSTEM PROMPTS (Optional Overrides)
# ====================================
# Leave empty to use defaults from code

AI_PROMPT_REFERENCE_COACH=
AI_PROMPT_VERIFICATION=
AI_PROMPT_AUTHENTICITY=
AI_PROMPT_INTELLIGENCE=

# ====================================
# FEATURE FLAGS
# ====================================
AI_STREAMING_ENABLED=true
AI_BATCH_PROCESSING_ENABLED=false
AI_ASYNC_PROCESSING_ENABLED=true
AI_MULTIMODAL_ENABLED=true

# ====================================
# TASK-SPECIFIC MODEL OVERRIDES
# ====================================
# Uncomment to override default model selection

# AI_MODEL_REFERENCE_ANALYSIS=claude-sonnet-4-5-20250514
# AI_MODEL_DEEPFAKE_DETECTION=claude-opus-4-20250514
# AI_MODEL_QUESTION_GENERATION=claude-sonnet-4-5-20250514
# AI_MODEL_SIMPLE_CLASSIFICATION=claude-haiku-4-5-20250514
# AI_MODEL_DOCUMENT_ANALYSIS=claude-opus-4-20250514
# AI_MODEL_REAL_TIME_CHAT=claude-haiku-4-5-20250514

# ====================================
# COST OPTIMIZATION SETTINGS
# ====================================
# Thresholds for automatic model downgrades based on cost
AI_COST_DAILY_LIMIT=500         # Daily spending limit in USD
AI_COST_MONTHLY_LIMIT=10000     # Monthly spending limit in USD
AI_COST_AUTO_DOWNGRADE=true     # Auto switch to cheaper models when approaching limits

# ====================================
# DEVELOPMENT & TESTING
# ====================================
AI_DRY_RUN_MODE=false           # Set to true to mock AI calls (no charges)
AI_DEBUG_MODE=false             # Enable detailed debugging output
AI_TEST_MODE=false              # Use test endpoints/models

# ====================================
# WEBHOOK & NOTIFICATIONS
# ====================================
AI_WEBHOOK_URL=                 # Webhook for AI events
AI_SLACK_WEBHOOK_URL=          # Slack notifications for alerts
AI_EMAIL_ALERTS=admin@deepref.ai

# ====================================
# NOTES & DOCUMENTATION
# ====================================
# 1. Model Versions (as of January 2025):
#    - Anthropic Claude Opus 4.1: Best for complex reasoning
#    - Anthropic Claude Sonnet 4.5: Balanced performance
#    - Anthropic Claude Haiku 4.5: Fast and cost-effective
#    - Google Gemini 3 Pro: Multimodal capabilities
#    - Google Gemini 3 Flash: Quick responses
#    - OpenAI GPT 5.1 Turbo: Tertiary fallback
#
# 2. Pricing Considerations:
#    - Opus 4.1: ~$15/$75 per million tokens (input/output)
#    - Sonnet 4.5: ~$3/$15 per million tokens
#    - Haiku 4.5: ~$0.25/$1.25 per million tokens
#    - Gemini 3 Pro: ~$2/$10 per million tokens
#    - Gemini 3 Flash: ~$0.15/$0.75 per million tokens
#    - GPT 5.1: ~$5/$15 per million tokens
#
# 3. Priority Order:
#    Primary: Anthropic (preferred for most tasks)
#    Secondary: Google (fallback for failures)
#    Tertiary: OpenAI (last resort)
#
# 4. Best Practices:
#    - Always set rate limits to prevent unexpected costs
#    - Enable monitoring and alerting for production
#    - Use caching for repeated queries
#    - Enable cost optimization for non-critical tasks
#    - Regularly review usage and adjust limits
#
# 5. Security:
#    - Never commit this file with real API keys
#    - Use environment-specific configurations
#    - Rotate API keys regularly
#    - Monitor for unusual usage patterns